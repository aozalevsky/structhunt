{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# We install postgres and its dev tools\n",
        "!sudo apt-get -y -qq update\n",
        "!sudo apt-get -y -qq install postgresql postgresql-server-dev-all\n",
        "\n",
        "#  Start postgres\n",
        "!sudo service postgresql start\n",
        "\n",
        "# Create user, password, and db!\n",
        "!sudo -u postgres psql -U postgres -c \"ALTER USER postgres PASSWORD 'postgres';\"\n",
        "!sudo -u postgres psql -U postgres -c 'DROP DATABASE IF EXISTS structdb;'\n",
        "!sudo -u postgres psql -U postgres -c 'CREATE DATABASE structdb;'\n",
        "\n",
        "!git clone --recursive https://github.com/lanterndata/lantern.git\n",
        "%cd lantern/\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake ..\n",
        "!sudo make install\n",
        "\n",
        "%cd ../../\n",
        "\n",
        "!pip install sentence-transformers==2.2.2 psycopg2-binary cohere openai langchain tiktoken faiss-gpu PyPDF2 pandas paperscraper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_PvxbgakTQF",
        "outputId": "90a6b586-360a-4a3a-ff1a-a0c3923a5c34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Starting PostgreSQL 14 database server\n",
            "   ...done.\n",
            "ALTER ROLE\n",
            "DROP DATABASE\n",
            "CREATE DATABASE\n",
            "fatal: destination path 'lantern' already exists and is not an empty directory.\n",
            "/content/lantern\n",
            "mkdir: cannot create directory ‘build’: File exists\n",
            "/content/lantern/build\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Build type: \n",
            "-- Found pg_config as /usr/bin/pg_config\n",
            "-- Found postgres binary at /usr/lib/postgresql/14/bin/postgres\n",
            "-- PostgreSQL version PostgreSQL 14.9 (Ubuntu 14.9-0ubuntu0.22.04.1) found\n",
            "-- PostgreSQL package library directory: /usr/lib/postgresql/14/lib\n",
            "-- PostgreSQL libraries: -lpgcommon -lpgport -lselinux -llz4 -lxslt -lxml2 -lpam -lssl -lcrypto -lgssapi_krb5 -lz -lreadline -lm\n",
            "-- PostgreSQL extension directory: /usr/share/postgresql/14/extension\n",
            "-- PostgreSQL linker options: -Wl,-Bsymbolic-functions;-flto=auto;-ffat-lto-objects;-flto=auto;-Wl,-z,relro;-Wl,-z,now;-L/usr/lib/llvm-14/lib;-Wl,--as-needed,\n",
            "-- PostgreSQL shared linker options: -Wl,-Bsymbolic-functions -flto=auto -ffat-lto-objects -flto=auto -Wl,-z,relro -Wl,-z,now -L/usr/lib/llvm-14/lib -Wl,--as-needed \n",
            "\u001b[0mCMake Deprecation Warning at third_party/usearch/c/CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Failure points are enabled.\n",
            "-- Configuring done (0.1s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/lantern/build\n",
            "[  9%] Built target usearch_c\n",
            "[ 95%] Built target lantern\n",
            "[100%] Built target phony_always_runs\n",
            "\u001b[36mInstall the project...\u001b[0m\n",
            "-- Install configuration: \"\"\n",
            "-- Installing: /usr/lib/postgresql/14/lib/lantern.so\n",
            "-- Set runtime path of \"/usr/lib/postgresql/14/lib/lantern.so\" to \"\"\n",
            "-- Installing: /usr/share/postgresql/14/extension/lantern.control\n",
            "-- Installing: /usr/share/postgresql/14/extension/lantern--0.0.4.sql\n",
            "-- Installing: /usr/share/postgresql/14/extension/lantern--0.0.4--latest.sql\n",
            "/content\n",
            "Requirement already satisfied: sentence-transformers==2.2.2 in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.10/dist-packages (2.9.9)\n",
            "Requirement already satisfied: cohere in /usr/local/lib/python3.10/dist-packages (4.32)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.330)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: paperscraper in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.35.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (1.11.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==2.2.2) (0.17.3)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.8.6)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n",
            "Requirement already satisfied: fastavro==1.8.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.8.2)\n",
            "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.57)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: arxiv>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from paperscraper) (2.0.0)\n",
            "Requirement already satisfied: pymed in /usr/local/lib/python3.10/dist-packages (from paperscraper) (0.8.9)\n",
            "Requirement already satisfied: scholarly==0.5.1 in /usr/local/lib/python3.10/dist-packages (from paperscraper) (0.5.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from paperscraper) (0.12.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from paperscraper) (3.7.1)\n",
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.10/dist-packages (from paperscraper) (0.11.9)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (from paperscraper) (0.0.1)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from scholarly==0.5.1->paperscraper) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from scholarly==0.5.1->paperscraper) (4.11.2)\n",
            "Requirement already satisfied: bibtexparser in /usr/local/lib/python3.10/dist-packages (from scholarly==0.5.1->paperscraper) (1.4.1)\n",
            "Requirement already satisfied: stem in /usr/local/lib/python3.10/dist-packages (from scholarly==0.5.1->paperscraper) (1.8.2)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.10/dist-packages (from scholarly==0.5.1->paperscraper) (1.3.0)\n",
            "Requirement already satisfied: PySocks in /usr/local/lib/python3.10/dist-packages (from scholarly==0.5.1->paperscraper) (1.7.1)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (from scholarly==0.5.1->paperscraper) (4.15.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from scholarly==0.5.1->paperscraper) (1.0.0)\n",
            "Requirement already satisfied: free-proxy in /usr/local/lib/python3.10/dist-packages (from scholarly==0.5.1->paperscraper) (1.1.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Requirement already satisfied: feedparser==6.0.10 in /usr/local/lib/python3.10/dist-packages (from arxiv>=1.4.2->paperscraper) (6.0.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.7.22)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser==6.0.10->arxiv>=1.4.2->paperscraper) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (2.1.0)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->paperscraper) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->paperscraper) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->paperscraper) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->paperscraper) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->paperscraper) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->paperscraper) (3.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers==2.2.2) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==2.2.2) (3.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->scholarly==0.5.1->paperscraper) (2.8.19.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->scholarly==0.5.1->paperscraper) (2.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from free-proxy->scholarly==0.5.1->paperscraper) (4.9.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium->scholarly==0.5.1->paperscraper) (0.23.1)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium->scholarly==0.5.1->paperscraper) (0.11.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly==0.5.1->paperscraper) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->scholarly==0.5.1->paperscraper) (1.3.0.post0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium->scholarly==0.5.1->paperscraper) (1.2.0)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->scholarly==0.5.1->paperscraper) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q22ZiEIBkOWW"
      },
      "outputs": [],
      "source": [
        "class Fragment:\n",
        "    id = \"\"\n",
        "    header = \"\"\n",
        "    content = \"\"\n",
        "    vector = \"\"\n",
        "\n",
        "    def __init__(self, id, header, content, vector):\n",
        "        self.id = id\n",
        "        self.header = header\n",
        "        self.content = content\n",
        "        self.vector = vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Publication:\n",
        "\n",
        "    id = \"\"\n",
        "    title = \"\"\n",
        "    pmc = \"\"\n",
        "    pubmed = \"\"\n",
        "    doi = \"\"\n",
        "\n",
        "    def __init__(self, id, title, pmc, pubmed, doi):\n",
        "        self.id = id\n",
        "        self.title = title\n",
        "        self.pmc = pmc\n",
        "        self.pubmed = pubmed\n",
        "        self.doi = doi"
      ],
      "metadata": {
        "id": "4Te46IiJkUgo"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "\n",
        "class Lantern:\n",
        "    conn = \"\"\n",
        "\n",
        "    def __init__(self, database=\"structdb\"):\n",
        "        self.conn = self.connect(database)\n",
        "        self.createTables()\n",
        "\n",
        "\n",
        "    def connect(self, database=\"structdb\"):\n",
        "        # We use the dbname, user, and password that we specified above\n",
        "        conn = psycopg2.connect(\n",
        "            dbname=database,\n",
        "            user=\"postgres\",\n",
        "            password=\"postgres\",\n",
        "            host=\"localhost\",\n",
        "            port=\"5432\" # default port for Postgres\n",
        "        )\n",
        "\n",
        "        cursor = conn.cursor()\n",
        "        # Execute the query to load the Lantern extension in\n",
        "        cursor.execute(\"CREATE EXTENSION IF NOT EXISTS lantern;\")\n",
        "\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "        return conn\n",
        "\n",
        "\n",
        "    def createTables(self):\n",
        "        self.createFragmentTable()\n",
        "        self.createPublicationTable()\n",
        "        self.createUnreadTable()\n",
        "\n",
        "    def createFragmentTable(self):\n",
        "        conn = self.conn\n",
        "        # Create the table\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        create_table_query = \"CREATE TABLE IF NOT EXISTS fragments (id text, header text, content text, vector real[]);\"\n",
        "\n",
        "        cursor.execute(create_table_query)\n",
        "\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "    def createPublicationTable(self):\n",
        "        conn = self.conn\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        create_table_query = \"CREATE TABLE IF NOT EXISTS publications (id text PRIMARY KEY, title text, pmc text, pubmed text, doi text);\"\n",
        "\n",
        "        cursor.execute(create_table_query)\n",
        "\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "    def createUnreadTable(self):\n",
        "        conn = self.conn\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        create_table_query = \"CREATE TABLE IF NOT EXISTS unread (id text PRIMARY KEY);\"\n",
        "        cursor.execute(create_table_query)\n",
        "\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "    def insertEmbedding(self, fragment: Fragment):\n",
        "        conn = self.conn\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        cursor.execute(\"INSERT INTO fragments (id, header, content, vector) VALUES (%s, %s, %s, %s);\", (fragment.id, fragment.header, fragment.content, fragment.vector))\n",
        "        cursor.execute(\"CREATE INDEX ON fragments USING hnsw (vector dist_cos_ops) WITH (dim=\" + str(fragment.VECTOR_LENGTH) + \");\")\n",
        "\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "    def insertEmbeddings(self, fragments: list):\n",
        "        if (len(fragments) < 1):\n",
        "            print(\"Empty List\")\n",
        "            return\n",
        "        conn = self.conn\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        queries=[]\n",
        "        for fragment in fragments:\n",
        "            queries.append((fragment.id, fragment.header, fragment.content, fragment.vector))\n",
        "\n",
        "        cursor.executemany(\"INSERT INTO fragments (id, header, content, vector) VALUES (%s, %s, %s, %s);\", queries)\n",
        "        cursor.execute(\"CREATE INDEX ON fragments USING hnsw (vector dist_cos_ops) WITH (dim=\" + str(len(fragments[0].vector)) + \");\")\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "    def insertPublication(self, p):\n",
        "        conn = self.conn\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        cursor.execute(\"INSERT INTO publications (id, title, pmc, pubmed, doi) VALUES (%s, %s, %s, %s, %s);\", (p.id, p.title, p.pmc, p.pubmed, p.doi))\n",
        "\n",
        "        query='INSERT INTO unread (id) VALUES (\\'{:s}\\');'.format(p.id)\n",
        "        cursor.execute(query)\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "\n",
        "\n",
        "    def getAllFragmentsOfPublication(self, id):\n",
        "        conn = self.conn\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        query='SELECT * FROM fragments WHERE id=\\'{:s}\\';'.format(id)\n",
        "        cursor.execute(query)\n",
        "        fragments = cursor.fetchall()\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "        fragmentObjects = []\n",
        "        for fragment in fragments:\n",
        "            fragmentObjects.append(Fragment(id, fragment[1], fragment[2], fragment[3]))\n",
        "\n",
        "        return fragmentObjects\n",
        "\n",
        "\n",
        "    def getUnreadPublication(self):\n",
        "        conn = self.conn\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        cursor.execute('SELECT * FROM publications AS p LEFT JOIN unread AS u ON u.id=p.id;')\n",
        "\n",
        "        publications = cursor.fetchall()\n",
        "\n",
        "        cursor.execute('DELETE FROM unread;')\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "\n",
        "        publicationObjects = []\n",
        "        for p in publications:\n",
        "            publicationObjects.append(Publication(p[0], p[1], p[2], p[3], p[4]))\n",
        "\n",
        "        return publicationObjects\n",
        "\n",
        "    def publicationExists(self, id):\n",
        "        conn = self.conn\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        query='SELECT COUNT(*) FROM publications WHERE id=\\'{:s}\\''.format(id)\n",
        "        cursor.execute(query)\n",
        "        count = cursor.fetchone()\n",
        "        conn.commit()\n",
        "        cursor.close()\n",
        "\n",
        "        return count[0] == 1\n",
        "\n"
      ],
      "metadata": {
        "id": "rF-UTDWxkZB8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "from paperscraper.pdf import save_pdf\n",
        "from paperscraper.get_dumps import biorxiv\n",
        "\n",
        "import openai\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain import PromptTemplate\n",
        "import PyPDF2\n",
        "\n",
        "# OpenAI Setup\n",
        "OPEN_API_KEY = \"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\"\n",
        "# openai.api_key = os.getenv(openai_api_key)\n",
        "os.environ['OPENAI_API_KEY'] = OPEN_API_KEY\n",
        "\n",
        "def scrapeBiorxiv(start, end, out_file):\n",
        "    filepath=out_file\n",
        "    biorxiv(begin_date=start, end_date=end, save_path=out_file)\n",
        "    retreiveTextFromPdf(filepath)\n",
        "\n",
        "def get_embeddings(fname):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    loader = TextLoader(fname)\n",
        "    documents = loader.load()\n",
        "    text_splitter = CharacterTextSplitter(separator = \".\",chunk_size = 1000, chunk_overlap=0)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    emb = OpenAIEmbeddings()\n",
        "    input_texts = [d.page_content for d in docs]\n",
        "\n",
        "    input_embeddings = emb.embed_documents(input_texts)\n",
        "    text_embeddings = list(zip(input_texts, input_embeddings))\n",
        "    return text_embeddings, emb\n",
        "\n",
        "def retreiveTextFromPdf(inp_file):\n",
        "\n",
        "\n",
        "    json = pd.read_json(path_or_buf=inp_file, lines=True)\n",
        "    lantern = Lantern()\n",
        "\n",
        "    for n, doi in enumerate(json['doi']):\n",
        "        print(n, doi)\n",
        "\n",
        "\n",
        "        ##NOTE: This is for example purpose only\n",
        "        if n > 10:\n",
        "            break\n",
        "\n",
        "        if lantern.publicationExists(doi):\n",
        "            continue\n",
        "\n",
        "        paper_data = {'doi': doi}\n",
        "        doi = doi.replace(\"/\", \"-\")\n",
        "        pdf_dir = './papers/'\n",
        "        if not os.path.exists(pdf_dir):\n",
        "            os.mkdir(pdf_dir)\n",
        "\n",
        "        pdfsavefile='./papers/' + doi +'.pdf'\n",
        "        save_pdf(paper_data, filepath=pdfsavefile)\n",
        "\n",
        "        # creating a pdf reader object\n",
        "        reader = PyPDF2.PdfReader(pdfsavefile)\n",
        "        save_txt_path = 'scrapped_txts/'\n",
        "        if not os.path.exists(save_txt_path):\n",
        "            os.mkdir(save_txt_path)\n",
        "        extract_text = ''\n",
        "        for page in reader.pages:\n",
        "            extract_text+=page.extract_text()\n",
        "\n",
        "        txt_file = str('{}.txt'.format(doi))\n",
        "        with open(save_txt_path+txt_file, 'w') as file:\n",
        "            file.write(extract_text)\n",
        "\n",
        "\n",
        "        txt_embs, emb = get_embeddings(save_txt_path+txt_file)\n",
        "\n",
        "        fragments = []\n",
        "        for txt, embs in txt_embs:\n",
        "            fragment = Fragment(doi, 'methods', txt, embs)\n",
        "            fragments.append(fragment)\n",
        "\n",
        "        title = \"\"\n",
        "        pmc = \"\"\n",
        "        pubmed = \"\"\n",
        "\n",
        "        publication = Publication(doi, title, pmc, pubmed, doi)\n",
        "\n",
        "        lantern.insertEmbeddings(fragments)\n",
        "        lantern.insertPublication(publication)\n",
        "\n",
        "        os.remove(pdfsavefile)\n",
        "\n",
        "start_date = \"2023-10-30\"\n",
        "end_date = \"2023-10-31\"\n",
        "out_file = \"bio.jsonl\"\n",
        "\n",
        "scrapeBiorxiv(start_date, end_date, out_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8PRbVJHka5-",
        "outputId": "5107f05c-aa4a-45fb-a457-1e214d65d2d7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "280it [00:16, 17.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 10.1101/2020.10.23.351742\n",
            "1 10.1101/2021.05.29.446196\n",
            "2 10.1101/2021.08.20.457147\n",
            "3 10.1101/2022.01.31.478514\n",
            "4 10.1101/2022.02.13.480270\n",
            "5 10.1101/2022.03.14.484202\n",
            "6 10.1101/2022.04.10.487810\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1135, which is longer than the specified 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 10.1101/2022.04.28.489897\n",
            "8 10.1101/2022.05.09.491115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1135, which is longer than the specified 1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9 10.1101/2022.05.28.493856\n",
            "10 10.1101/2022.06.08.495145\n",
            "11 10.1101/2022.06.30.498314\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo -u postgres pg_dump structdb > structdb.sql"
      ],
      "metadata": {
        "id": "NIRYlEyrALeq"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}